{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed798388-c907-4905-9e5d-76891490b222",
   "metadata": {},
   "source": [
    "### Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6248e53-5259-4bea-bc6b-0ac9e66fd64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install torch --quiet --quiet\n",
    "%pip install coba --quiet --quiet\n",
    "%pip install scipy --quiet --quiet\n",
    "%pip install numpy --quiet --quiet\n",
    "%pip install matplotlib --quiet --quiet\n",
    "%pip install transformers --quiet --quiet\n",
    "%pip install xformers --quiet --quiet\n",
    "%pip install einops --quiet --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc665e0-f5ee-4e4f-a478-72b9b0ebe4f0",
   "metadata": {},
   "source": [
    "### TODO\n",
    "+ Change all 'reward' names to 'loss'\n",
    "+ Move MyRewardPredictor back into this notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23509513-8f3c-4383-aa54-f4326d182fc5",
   "metadata": {},
   "source": [
    "### Run Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4293c945-f088-4b32-b492-9e83b249eb20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-19 11:07:02 -- pid-18980  -- Experiment Started\n",
      "2023-07-19 11:07:02 -- pid-29792  -- Recording Evaluator 0 parameters... (0.0 seconds) (completed)\n",
      "2023-07-19 11:07:04 -- pid-26532  -- Recording Learner 0 parameters... (0.0 seconds) (completed)\n",
      "2023-07-19 11:07:04 -- pid-26532  -- Recording Environment 0 parameters... (0.0 seconds) (completed)\n",
      "2023-07-19 11:07:04 -- pid-29792  -- Recording Learner 2 parameters... (0.0 seconds) (completed)\n",
      "2023-07-19 11:07:04 -- pid-7608   -- Recording Learner 1 parameters... (0.0 seconds) (completed)\n",
      "2023-07-19 11:07:04 -- pid-23276  -- Recording Learner 3 parameters... (0.0 seconds) (completed)\n",
      "2023-07-19 11:07:05 -- pid-26532  -- Peeking at Environment 0... (0.78 seconds) (completed)\n",
      "2023-07-19 11:07:05 -- pid-23276  -- Peeking at Environment 0... (0.8 seconds) (completed)\n",
      "2023-07-19 11:07:05 -- pid-29792  -- Peeking at Environment 0... (0.82 seconds) (completed)\n",
      "2023-07-19 11:07:05 -- pid-7608   -- Peeking at Environment 0... (0.86 seconds) (completed)\n",
      "2023-07-19 11:14:06 -- pid-23276  -- Evaluating Learner 3 on Environment 0... (420.43 seconds) (completed)\n",
      "2023-07-19 11:14:06 -- pid-7608   -- Evaluating Learner 2 on Environment 0... (420.42 seconds) (completed)\n",
      "2023-07-19 11:16:38 -- pid-29792  -- Evaluating Learner 1 on Environment 0... (572.28 seconds) (completed)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import coba as cb\n",
    "import numpy as np\n",
    "from CappedIGW import CappedIGW\n",
    "from ScaledL1Loss import MakeLosses\n",
    "from PowerScheduler import PowerScheduler\n",
    "from MyRewardPredictor import MyRewardPredictor\n",
    "from UniformReferencePolicy import UniformReferencePolicy\n",
    "\n",
    "#these values are specific to openml dataset 41540\n",
    "n_context_dim, n_action_dim = 22, 1\n",
    "tzero = 100\n",
    "lr = 1e-2\n",
    "batch_size = 8\n",
    "n_batches = 2_500\n",
    "n_processes = 4\n",
    "\n",
    "if n_processes > 1:\n",
    "    torch.set_num_threads(1)\n",
    "\n",
    "fhat = MyRewardPredictor(\n",
    "    numrff=1024,\n",
    "    sigma=1e-1,\n",
    "    in_features=n_context_dim+n_action_dim,\n",
    "    opt_factory=lambda params: torch.optim.Adam(params,lr=lr),\n",
    "    sched_factory=lambda opt: torch.optim.lr_scheduler.LambdaLR(opt, lr_lambda=PowerScheduler(tzero,-.5))\n",
    ")\n",
    "\n",
    "cb.Environments.cache_dir('.coba_cache')\n",
    "\n",
    "env = cb.Environments.from_openml(data_id=41540,take=batch_size*n_batches).scale().filter(MakeLosses()).batch(batch_size)\n",
    "lrn = [\n",
    "    CappedIGW(mu=UniformReferencePolicy(), fhat=fhat, tau=50, gamma_scheduler = PowerScheduler(tz,.5)) \n",
    "    for tz in np.geomspace(1e-6,1e-3,4)\n",
    "]\n",
    "\n",
    "result = cb.Experiment(env,lrn).run(processes=n_processes)\n",
    "result.plot_learners(span=100)\n",
    "result.plot_learners(y='reward_prediction_loss', span=100)\n",
    "result.plot_learners(y='reward_prediction_regret', span=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbbe692d-899a-4e5e-81c5-ae6690ed1f6e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
